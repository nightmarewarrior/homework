{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nightmarewarrior/homework/blob/main/%D0%AF%D0%B7%D1%8B%D0%BA%D0%BE%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fad453",
      "metadata": {
        "id": "00fad453"
      },
      "source": [
        "# Домашнее задание № 4. Языковые модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "YknVG6lXsoNC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YknVG6lXsoNC",
        "outputId": "abeacf05-966f-4898-dc37-702957bab85b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install razdel\n",
        "\n",
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d056af4",
      "metadata": {
        "id": "5d056af4"
      },
      "source": [
        "## Задание 1 (8 баллов)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f532a8",
      "metadata": {
        "id": "d1f532a8"
      },
      "source": [
        "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de743d1d",
      "metadata": {
        "id": "de743d1d"
      },
      "source": [
        "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
        "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели.\n",
        "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
        "\n",
        "\n",
        "Подсказки:  \n",
        "    - нужно будет добавить еще один тэг \\<start>  \n",
        "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хронить биграмы, а по колонкам униграммы\n",
        "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
        "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d078056d",
      "metadata": {
        "id": "d078056d"
      },
      "outputs": [],
      "source": [
        "with open('2ch_corpus.txt', encoding='utf-8') as f:\n",
        "    dvach = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "6afcef88",
      "metadata": {
        "id": "6afcef88"
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text\n",
        "\n",
        "#norm_dvach = normalize(dvach)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ZGHgfB9n9XOu",
      "metadata": {
        "id": "ZGHgfB9n9XOu"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "sentences_dvach = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach[:5000000])]\n",
        "\n",
        "unigrams_dvach = Counter()\n",
        "bigrams_dvach = Counter()\n",
        "trigrams_dvach = Counter()\n",
        "\n",
        "for sentence in sentences_dvach:\n",
        "    unigrams_dvach.update(sentence)\n",
        "    #bigrams_dvach.update(ngrammer(sentence, n=2))\n",
        "    bigrams_dvach.update(ngrammer(sentence))\n",
        "    trigrams_dvach.update(ngrammer(sentence, n=3))\n",
        "\n",
        "matrix_dvach = lil_matrix((len(bigrams_dvach), len(unigrams_dvach)))\n",
        "\n",
        "id2word_dvach = list(unigrams_dvach)\n",
        "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
        "\n",
        "id2bigrams_dvach = list(bigrams_dvach)\n",
        "word2idbigrams_dvach = {word:i for i, word in enumerate(id2bigrams_dvach)}\n",
        "\n",
        "for ngram in trigrams_dvach:\n",
        "    bigram, unigram = ngram.rsplit(maxsplit=1)\n",
        "    #if word_bigram in word2idbigrams_dvach and word_unigram in word2id_dvach:\n",
        "    matrix_dvach[word2idbigrams_dvach[bigram], word2id_dvach[unigram]] = (\n",
        "            trigrams_dvach[ngram] / bigrams_dvach[bigram]\n",
        "        )\n",
        "matrix_dvach = csc_matrix(matrix_dvach)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "oraxhPIFGyGC",
      "metadata": {
        "id": "oraxhPIFGyGC"
      },
      "outputs": [],
      "source": [
        "def apply_temperature(probas, temperature):\n",
        "    log_probas = np.log(np.maximum(probas, 1e-10))\n",
        "    adjusted_log_probas = log_probas / temperature\n",
        "    exp_probas = np.exp(adjusted_log_probas)\n",
        "    adjusted_probabilities = exp_probas / np.sum(exp_probas)\n",
        "    return adjusted_probabilities\n",
        "\n",
        "def generate_temp(matrix, id2word, id2bigrams, word2id, word2idbigrams, n=100, start='<start> <start>', temperature=1.):\n",
        "    text = start.split()\n",
        "    current_idx = word2idbigrams[start]\n",
        "\n",
        "    for i in range(n):\n",
        "        chosen = np.random.choice(matrix.shape[1], p=apply_temperature(matrix[current_idx].toarray()[0], temperature=temperature))\n",
        "        text.append(id2word[chosen])\n",
        "\n",
        "        if id2word[chosen] == '<end>':\n",
        "            current_idx = word2idbigrams['<start> <start>']\n",
        "            text.extend(['<start>', '<start>'])\n",
        "        else:\n",
        "            current_idx = word2idbigrams[' '.join(text[-2:])]\n",
        "    return ' '.join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "84rHXLuAJ9-3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84rHXLuAJ9-3",
        "outputId": "3911a717-052b-483d-a3bd-20f7f5ae7e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " а я вот например автократ от милитаристов может построить крупный корабль у тебя есть полезные проекты на крестах пхп или тому подобном говне совковые традиции где нужно сидеть строго 8 часов в день \n",
            "  а если я не знаю как\n"
          ]
        }
      ],
      "source": [
        "print(generate_temp(matrix_dvach, id2word_dvach, word2id_dvach, id2bigrams_dvach, word2idbigrams_dvach,  n=40, temperature=0.09).replace('<start> <start>', '').replace('<end>', '\\n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IG1kpma7pMM-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG1kpma7pMM-",
        "outputId": "04b686f9-d60d-4a73-9642-50e08e8520bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " и динамичным главным героем че бля самый смешной здесь \n",
            "  согласно исландским сагам харальд прекрасноволосый имел много жен и детей давай стругать \n",
            "  проиграл со внезапной метафоры на карьерную лестницу\n"
          ]
        }
      ],
      "source": [
        "print(generate_temp(matrix_dvach, id2word_dvach, word2id_dvach, id2bigrams_dvach, word2idbigrams_dvach,  n=40, temperature=1.0).replace('<start> <start>', '').replace('<end>', '\\n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HKfIAzSjq6Cm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKfIAzSjq6Cm",
        "outputId": "804d1a71-c34a-45fd-958e-e7e681e896d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " get out of her life \n",
            "  сайдомв смысле спиноффом \n",
            "  но мамку зато видел \n",
            "  поэтому думаю вписать еще одну годную свежую метроидванию вспомнил визульно криповатая как метроиды или какая-нибудь contra но если уж вы все знаете \n",
            "  ук ебут\n"
          ]
        }
      ],
      "source": [
        "print(generate_temp(matrix_dvach, id2word_dvach, word2id_dvach, id2bigrams_dvach, word2idbigrams_dvach,  n=40, temperature=1.4).replace('<start> <start>', '').replace('<end>', '\\n'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему-то выше 1.4 температура не повышается - выдает KeyError.. И как её исправить я не знаю.."
      ],
      "metadata": {
        "id": "ampnZGVu_Duz"
      },
      "id": "ampnZGVu_Duz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o539Ncjs8-Vu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o539Ncjs8-Vu",
        "outputId": "3688b06d-e9f0-49cf-cc65-2f101a87bbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(len(word2id_dvach) < len(word2idbigrams_dvach))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "n-xWM3kZq4Rz",
      "metadata": {
        "id": "n-xWM3kZq4Rz"
      },
      "outputs": [],
      "source": [
        "def perplexity(logp, N):\n",
        "    return np.exp((-1/N) * logp)\n",
        "\n",
        "def compute_join_proba_markov_assumption(text, matrix, word2id, word2idbigrams, trigrams):\n",
        "    tokens = ['<start>'] + ['<start>'] + normalize(text) + ['<end>']\n",
        "    trigrams_tokens = ngrammer(tokens, n=3)\n",
        "    log_prob = 0\n",
        "    for trigram in trigrams_tokens:\n",
        "        bigram, unigram = trigram.rsplit(maxsplit=1)\n",
        "        if bigram in word2idbigrams and unigram in word2id:\n",
        "            bigram_idx = word2idbigrams[bigram]\n",
        "            unigram_idx = word2id[unigram]\n",
        "            prob = matrix[bigram_idx, unigram_idx]\n",
        "            if prob > 0:\n",
        "                log_prob += np.log(prob)\n",
        "            else:\n",
        "                log_prob += np.log(2e-5)\n",
        "        else:\n",
        "            log_prob += np.log(2e-5)\n",
        "    return log_prob, len(tokens) - 3\n",
        "\n",
        "\n",
        "corpus = dvach[5000000:]\n",
        "norm = normalize(corpus)\n",
        "vocab = Counter(norm)\n",
        "probas = Counter({word:c/len(norm) for word, c in vocab.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vF33u-Smtqun",
      "metadata": {
        "id": "vF33u-Smtqun"
      },
      "outputs": [],
      "source": [
        "text = (generate_temp(matrix_dvach, id2word_dvach, word2id_dvach, id2bigrams_dvach, word2idbigrams_dvach).replace('<start> <start>', '').replace('<end>', '\\n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K68IYPS8y_U2",
      "metadata": {
        "id": "K68IYPS8y_U2"
      },
      "outputs": [],
      "source": [
        "ps = []\n",
        "for sent in sent_tokenize(dvach[:5000000]):\n",
        "  prob, N = compute_join_proba_markov_assumption(\n",
        "        sent, matrix_dvach, word2id_dvach, word2idbigrams_dvach, trigrams_dvach\n",
        "        )\n",
        "  if not N:\n",
        "        continue\n",
        "  ps.append(perplexity(prob, N))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OGn1NPKKgEOX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGn1NPKKgEOX",
        "outputId": "a47b2997-fb79-449b-e025-db724e51d10d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1448.3196692714876"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(ps)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e0a8dd5",
      "metadata": {
        "id": "8e0a8dd5"
      },
      "source": [
        "## Задание № 2* (2 балла)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f733858c",
      "metadata": {
        "id": "f733858c"
      },
      "source": [
        "Измените функцию generate_with_beam_search так, чтобы она работала с моделью, которая учитывает два предыдущих слова.\n",
        "Сравните получаемый результат с первым заданием.\n",
        "Также попробуйте начинать генерацию не с нуля (подавая \\<start> \\<start>), а с какого-то промпта. Но помните, что учитываться будут только два последних слова, так что не делайте длинные промпты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c426746a",
      "metadata": {
        "id": "c426746a"
      },
      "outputs": [],
      "source": [
        "class Beam:\n",
        "    def __init__(self, sequence: list, score: float):\n",
        "        self.sequence: list = sequence\n",
        "        self.score: float = score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_beam_search(matrix, id2word, id2bigrams, word2id, word2idbigrams, n=100, max_beams=5, start='<start> <start>'):\n",
        "    initial_node = Beam(sequence=start.split(), score=np.log1p(0))\n",
        "    beams = [initial_node]\n",
        "\n",
        "    for i in range(n):\n",
        "        new_beams = []\n",
        "        for beam in beams:\n",
        "            if beam.sequence[-1] == '<end>':\n",
        "                new_beams.append(beam)\n",
        "                continue\n",
        "            last_bigram = ' '.join(beam.sequence[-2:])\n",
        "            if last_bigram not in word2idbigrams:\n",
        "                continue\n",
        "            last_id = word2idbigrams[last_bigram]\n",
        "            probas = matrix[last_id].toarray()[0]\n",
        "            top_idxs = probas.argsort()[:-(max_beams+1):-1]\n",
        "            for top_id in top_idxs:\n",
        "                if not probas[top_id]:\n",
        "                    break\n",
        "                new_sequence = beam.sequence + [id2word[top_id]]\n",
        "                new_score = (beam.score + np.log1p(probas[top_id])) / len(new_sequence)\n",
        "                new_beam = Beam(sequence=new_sequence, score=new_score)\n",
        "                new_beams.append(new_beam)\n",
        "        beams = sorted(new_beams, key=lambda x: x.score, reverse=True)[:max_beams]\n",
        "        if all(beam.sequence[-1] == '<end>' for beam in beams):\n",
        "            break\n",
        "    sorted_sequences = sorted(beams, key=lambda x: x.score, reverse=True)\n",
        "    sorted_sequences = [\" \".join(beam.sequence) for beam in sorted_sequences]\n",
        "    return sorted_sequences"
      ],
      "metadata": {
        "id": "UVzdL3JnuO8G"
      },
      "id": "UVzdL3JnuO8G",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = generate_with_beam_search(matrix_dvach, id2word_dvach, word2id_dvach, id2bigrams_dvach, word2idbigrams_dvach)\n"
      ],
      "metadata": {
        "id": "1CxmiR9WP_oz"
      },
      "id": "1CxmiR9WP_oz",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "cKXLaETL-WNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93a6012-20f5-4e0f-db9c-d83b5ad3ab91"
      },
      "id": "cKXLaETL-WNU",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> <start> я не знаю что это за хуйня <end>',\n",
              " '<start> <start> я не знаю <end>',\n",
              " '<start> <start> ну и что <end>',\n",
              " '<start> <start> я не знаю что это не так <end>',\n",
              " '<start> <start> я не знаю как это будет называться <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_with_beam_search(matrix_dvach, id2word_dvach, word2id_dvach, id2bigrams_dvach, word2idbigrams_dvach, start='<start> анимублядский')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZlGpKJunQvw",
        "outputId": "9a51cf18-855d-4376-8d38-dd64f39ad0dd"
      },
      "id": "MZlGpKJunQvw",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> анимублядский webm-треддля приличных анимублядей и прочих аутистов <end>',\n",
              " '<start> анимублядский webm-треддля приличных анимублядей и прочих лулзов <end>',\n",
              " '<start> анимублядский webm-треддля приличных анимублядей и прочих прототипов этахудожник <end>',\n",
              " '<start> анимублядский webm-треддля приличных анимублядей и прочих прототипов остальные повторяют <end>',\n",
              " '<start> анимублядский webm-треддля приличных анимублядей и прочих подобных по сложности данжей <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_with_beam_search(matrix_dvach, id2word_dvach, word2id_dvach, id2bigrams_dvach, word2idbigrams_dvach, start='<start> <start> тред не читал')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4UbThyDnrd_",
        "outputId": "b900b9a2-11b8-469e-bfe0-4d779a22a312"
      },
      "id": "a4UbThyDnrd_",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> <start> тред не читал почитай русскую классику типа достоевского чехова пушкина <end>',\n",
              " '<start> <start> тред не читал почитай русскую классику <end>',\n",
              " '<start> <start> тред не читал <end>',\n",
              " '<start> <start> тред не читал джойса но полагаю все это время в тюрьме накопится желание калечить и убивать уже никого небыло онлайн громили неписей <end>',\n",
              " '<start> <start> тред не читал джойса но полагаю все это время в тюрьме накопится желание калечить и убивать уже никого не ебал педоборец так как они вообще не понимаю <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}